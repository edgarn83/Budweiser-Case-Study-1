---
title: "Budwiser Case Study 01 by Megan R. and Egar N."
author: "Edgar Nunez and Megan Riley"
date: "10/5/2019"
output: html_document
---

```{r setup, warnings = FALSE, cache=TRUE}
knitr::opts_chunk$set(echo = TRUE)
install.packages("sqldf")
install.packages("stringr")


#Loading Libraries
library(stringr)
library(sqldf)
library(tidyverse)
library(ggplot2)
library(GGally)
library(dplyr)

knitr::opts_chunk$set(echo = TRUE)

# Read in data
BeersData = read_csv("Beers.csv")
BreweriesData = read_csv("Breweries.csv")


```


##Here we present a breakdown of the number of breweries in each state

```{r warnings = FALSE}
#How Many Breweries in Each State? 
library(tidyverse)
#At the moment the file wont knit without reloading tidyverse here
#Should find a permanent fix for the final rmd presentation.
BreweriesData %>% group_by(State) %>% summarise(n = n())


```


###Here we present a consolidated view of the beer data with the breweries data

```{r warnings = FALSE, cache=TRUE}
#Merge the Data 
BeerWithBreweries = merge(BeersData,BreweriesData, by.x = "Brewery_id", by.y = "Brew_ID")
colnames(BeerWithBreweries)[colnames(BeerWithBreweries)=="Name.x"] <- "Beer_Name"
colnames(BeerWithBreweries)[colnames(BeerWithBreweries)=="Name.y"] <- "Brewery_Name"

```


## The first order of business once we have a clean data set is to discover what we can about this data.  We use exploratory data analysis for this purpose.
```{r eda, include=TRUE}
# Look at some possible associations between variables
ggplot(BeersData, aes(x = ABV, y = IBU)) +
  geom_point () +
  geom_smooth (method='lm') +
  labs (
    title = "ABV and IBU relationship",
    subtitle = "Strong Positive Correlation - Needs Transformation",
    x = "ABV",
    y = "IBU")

ggplot(BeersData, aes(x = Style, y = IBU)) +
  geom_point () +
  geom_smooth () +
  labs (
    title = "Style and IBU relationship",
    subtitle = "No apparent Correlation",
    x = "Style",
    y = "IBU")

ggplot(BeersData, aes(x = Brewery_id, y = IBU)) +
  geom_point () +
  geom_smooth () +
  labs (
    title = "Brewery ID and IBU relationship",
    subtitle = "Low linear Correlation - No Transformation required",
    x = "Brewery ID",
    y = "IBU")

ggplot(BeersData, aes(x = Beer_ID, y = IBU)) +
  geom_point () +
  geom_smooth () +
  labs (
    title = "Beer ID and IBU relationship",
    subtitle = "Low Correlation - Needs Transformation",
    x = "Beer_ID",
    y = "IBU")

ggplot(BeersData, aes(x = Ounces, y = IBU)) +
  geom_point () +
  geom_smooth () +
  labs (
    title = "Ounces and IBU relationship",
    subtitle = "No apparent Correlation",
    x = "Ounces",
    y = "IBU")

ggplot(BeersData, aes(x = Name, y = IBU)) +
  geom_point () +
  geom_smooth () +
  labs (
    title = "Name and IBU relationship",
    subtitle = "No apparent Correlation",
    x = "Name",
    y = "IBU")

```


### Based on this analysis,IBU has a linear relationship with ABV. However, there is unequal variance in between beers' IBU with lower and higher ABV.

### To address the Missing Values in each Column we chose to impute the NA value with the median of the existing variables, because IBU showed a strong positive correlation with BVA.

###Analysis Question Three
##The Missing Values are addressed before any additional data manipulation takes place so work ##does not have to be redone.

```{r warnings = FALSE}
#Address the Missing Values in Each Column
#Copy Made to compare differences after Imputation
BeersCopy = BeersData

#Replace the NAs with the respective Medians
MedianIBU <- median(BeersData$IBU, na.rm = TRUE)
MedianABV <- median(BeersData$ABV, na.rm = TRUE) 

#Replace IBU
NAIndicesIBU = which(is.na(BeersData$IBU))
for(i in NAIndicesIBU){
  BeersData$IBU[i] = MedianIBU
}

#ReplaceABV
NAIndicesABV = which(is.na(BeersData$ABV))
for(i in NAIndicesABV){
  BeersData$ABV[i] = MedianABV
}

#Example of replacing values with regression model
BeersTemp = BeersCopy
#this is an unimputed data set
lmibu = lm(BeersTemp$IBU ~BeersTemp$ABV, data = BeersTemp)
predicted = predict(lmibu, BeersTemp)

NaTempIndices = which(is.na(BeersTemp$IBU))
for(i in NaTempIndices){
  BeersTemp$IBU[i] = predicted[i]
}
```


### Comparison of the median alcohol content and international bitterness unit (IBU) for each state

```{r}
library(ggthemes)
MedianABV = BeerWithBreweries %>% group_by(State) %>% summarise(MedABV = median(ABV, na.rm = TRUE))
MedianABV %>% ggplot(aes(x = State, y = MedABV)) + geom_bar(stat = "identity", fill = "light green") +
  ylab("Median ABV") + ggtitle("Median Beer ABV by State") + theme_clean()

MedianIBU = BeerWithBreweries %>% group_by(State) %>% summarise(MedIBU = median(IBU, na.rm = TRUE))
MedianIBU %>% ggplot(aes(x = State, y = MedIBU)) + geom_bar(stat = "identity", fill = "light blue")+
  ylab("Median State IBU") + ggtitle("Median Beer IBU by State") + theme_clean()

```



### State with the maximum alcoholic (ABV) beer and state with the most bitter (IBU) beer

```{r warnings = FALSE}
#Which state has the maximum ABV beer. 
ABVMax = which.max(BeerWithBreweries$ABV)
print(BeerWithBreweries[ABVMax,c(4,8,10)])

#Which state has the most bitter IBU beer? 
IBUMax = which.max(BeerWithBreweries$IBU)
print(BeerWithBreweries[IBUMax,c(5,8,10)])

```

### Summary statistics and distribution of the ABV

```{r warnings = FALSE, message=FALSE}
#Summary Statistics and Distribution of the ABV variable
BeersData %>% ggplot(aes(x = ABV)) + geom_histogram(stat = "count")
summary(BeersData$ABV)

```

### The is an apparent strong positive correlation between the bitterness of the beer and its alcoholic content

```{r warnings = FALSE}
#Relationship betwen the bitterness of the beer and its alcoholic content, Scaatter plot and discussing 
BeersData %>% ggplot(aes(x = ABV, y = IBU, color = as.factor(Ounces))) + geom_point() +
  ggtitle("Beer IBU by ABV colored by Ounces")

```


### Answerto question eight
```{r}
table(BeersData$Style)
BeersData %>% select(Name, Beer_ID, ABV, IBU, Brewery_id, Style, Ounces) %>% 
filter(str_detect(Style, "India Pale Ale"))

BeersData %>% select(Name, Beer_ID, ABV, IBU, Brewery_id, Style, Ounces) %>% 
filter(str_detect(Style, "IPA"))

BeersData %>% select(Name, Beer_ID, ABV, IBU, Brewery_id, Style, Ounces) %>% 
dplyr::filter(!str_detect(Style, "IPA"))

set.seed(9850)
gp <- runif(nrow(BeersData))
head(BeersData)
BeersData <- BeersData[order(gp),] #Scramble the beers n the data set

BeersData$Style <- as.factor(BeersData$Style)
str(BeersData)
summary(BeersData[, c(1, 2, 3, 4, 5)])

#Normalize numeric features (variable) to have similar scale
normalize <- function(x) (x - min(x))/(max(x)-min(x))
normalize(BeersData[, 2:5])

BeersData_norm <- as.data.frame(lapply(BeersData[,c(2,3,4,5)], normalize))
BeersData_norm$Style <- BeersData$Style
str(BeersData_norm)
summary(BeersData_norm)

#Create training and test data sets with 70:30 split
#Training data set uses rows 1 - 1687 from the normalized dataset and all the columns for the train dataset
 #Test data set Uses rows 1688 - 2410 from the normalized dataset and all the columns for the test dtaset
BeersData_train <- BeersData_norm[1:1687, ]
BeersData_test <- BeersData_norm[1688:2410, ]

#Target feature (Style) training data set uses rows 1 - 1687 and column 6 from theoriginal dataset
#Target feature (Style) testing data set uses rows 1688 - 2410 and column 6 from the original dataset
BeersData_train_target <- BeersData[1:1687, 6]
BeersData_test_target <- BeersData[1688:2410, 6]

#Load the class package
require(class)


#The knn algorithm receives the training, testing and training target data frmes. In addition to the k - a plce holder for how many neighbors we want the algorithm to use
# A rule of thum is to set k = to the sqrt(total number of obs.) and preferably use an odd number to help knn break a potential tie

sqrt(2410)

# Generate a prediction fro the classification of all the values in the test dataframe
m1 <- knn(train = BeersData_train, test = BeersData_test, cl=BeersData_train_target, k=50)

#Use a confusion matrix to evaluate how well knn did at classifying those 21 flowers in the test data set
#Use the target test data set in the X axis, and put m1 in the Y axis
table(BeersData_test_target, m1) 

#Values in the diagonal of the confusion matrix are the correctly predicted, off the diagonal are values incorrectly predicted
# Target variables that categorical must be coded as factor in R for the KNN algorithm to be sucessful
m1


```

>>>>>>> Stashed changes
